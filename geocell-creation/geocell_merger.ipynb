{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a71f822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import unary_union\n",
    "import numpy as np\n",
    "from shapely.strtree import STRtree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450414d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/pyogrio/raw.py:198: RuntimeWarning: This version of GeoPackage user_version=0x000028A0 (10400, v1.4.0) on '../resources/gadm_level2.gpkg' may only be partially supported\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           GID_2        NAME_2    GID_1              NAME_1 GID_0    NAME_0  \\\n",
      "48128  ZWE.9.5_2  Gwanda Urban  ZWE.9_1  Matabeleland South   ZWE  Zimbabwe   \n",
      "48129  ZWE.9.6_2        Insiza  ZWE.9_1  Matabeleland South   ZWE  Zimbabwe   \n",
      "48130  ZWE.9.7_2        Mangwe  ZWE.9_1  Matabeleland South   ZWE  Zimbabwe   \n",
      "48131  ZWE.9.8_2        Matobo  ZWE.9_1  Matabeleland South   ZWE  Zimbabwe   \n",
      "48132  ZWE.9.9_2      Plumtree  ZWE.9_1  Matabeleland South   ZWE  Zimbabwe   \n",
      "\n",
      "                                                geometry  \n",
      "48128  MULTIPOLYGON (((29.00187 -20.95896, 29.00164 -...  \n",
      "48129  MULTIPOLYGON (((29.35744 -21.02481, 29.35821 -...  \n",
      "48130  MULTIPOLYGON (((27.81436 -21.19368, 27.81452 -...  \n",
      "48131  MULTIPOLYGON (((28.45053 -21.64326, 28.44812 -...  \n",
      "48132  MULTIPOLYGON (((27.83201 -20.57665, 27.82436 -...  \n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file(\"../resources/gadm_level2.gpkg\")\n",
    "print(gdf.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e64ec4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 IMG_ID        AUTHOR        LAT         LON  S3_Label  \\\n",
      "0  92_17_5276763594.jpg  42441750@N03  38.685568 -109.532951       1.0   \n",
      "1  0d_ce_6392770405.jpg  68149505@N00  34.933793  103.692741       0.0   \n",
      "2  2a_88_5268406683.jpg  84867026@N00  39.983433  -75.243301       0.0   \n",
      "3  82_be_2515710583.jpg  75292316@N00  39.306094  -84.379291       1.0   \n",
      "4  03_05_9498368699.jpg  61068860@N00   9.186625  123.581597       1.0   \n",
      "\n",
      "   S16_Label  S365_Label   Prob_indoor  Prob_natural  Prob_urban  \\\n",
      "0        7.0       289.0  1.739840e-04      0.897409    0.102417   \n",
      "1        1.0       122.0  9.968868e-01      0.000578    0.002535   \n",
      "2        0.0       128.0  7.201538e-01      0.034871    0.244975   \n",
      "3        6.0       145.0  9.050690e-05      0.516982    0.482927   \n",
      "4        8.0        36.0  9.902391e-07      0.999983    0.000016   \n",
      "\n",
      "  neighbourhood          city               county         state  \\\n",
      "0           NaN           NaN         Grand County          Utah   \n",
      "1           NaN        Lianlu        Kangle County         Gansu   \n",
      "2     Overbrook  Philadelphia  Philadelphia County  Pennsylvania   \n",
      "3           NaN           NaN        Butler County          Ohio   \n",
      "4           NaN      Siquijor                  NaN      Siquijor   \n",
      "\n",
      "            region        country country_code  continent  \\\n",
      "0              NaN  United States           us        NaN   \n",
      "1           Linxia          China           cn        NaN   \n",
      "2              NaN  United States           us        NaN   \n",
      "3              NaN  United States           us        NaN   \n",
      "4  Central Visayas    Philippines           ph        NaN   \n",
      "\n",
      "                                                 URL  \\\n",
      "0  http://farm6.staticflickr.com/5042/5276763594_...   \n",
      "1  http://farm8.staticflickr.com/7172/6392770405_...   \n",
      "2  http://farm6.staticflickr.com/5045/5268406683_...   \n",
      "3  http://farm3.staticflickr.com/2389/2515710583_...   \n",
      "4  http://farm4.staticflickr.com/3800/9498368699_...   \n",
      "\n",
      "                                             caption  \n",
      "0  A geo-tagged image taken in Utah, United State...  \n",
      "1  A geo-tagged image taken in Lianlu, Gansu, Chi...  \n",
      "2  A geo-tagged image taken in Philadelphia, Penn...  \n",
      "3  A geo-tagged image taken in Ohio, United State...  \n",
      "4  A geo-tagged image taken in Siquijor, Siquijor...  \n"
     ]
    }
   ],
   "source": [
    "df_images = pd.read_csv(\"../resources/mp16_combined.csv\");\n",
    "print(df_images.head());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3878dfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   GID_2 NAME_2  image_count\n",
      "0                        464\n",
      "1                          0\n",
      "2                          0\n",
      "3                          2\n",
      "4                        523\n",
      "5                         26\n",
      "6                        129\n",
      "7                        729\n",
      "8                          0\n",
      "9                         19\n",
      "10                        22\n",
      "11                        67\n",
      "12                      1109\n",
      "13                        39\n",
      "14                         1\n",
      "15                         0\n",
      "16                        90\n",
      "17                       287\n",
      "18                      2590\n",
      "19                        52\n"
     ]
    }
   ],
   "source": [
    "geometry = [Point(xy) for xy in zip(df_images['LON'], df_images['LAT'])]\n",
    "gdf_images = gpd.GeoDataFrame(df_images, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "joined = gpd.sjoin(gdf_images, gdf, how='left', predicate='within')\n",
    "\n",
    "image_counts = joined.groupby(joined.index_right).size()\n",
    "\n",
    "gdf['image_count'] = gdf.index.map(image_counts).fillna(0).astype(int)\n",
    "\n",
    "print(gdf[['GID_2', 'NAME_2', 'image_count']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a61ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_small_cells_fast(gdf, min_count=50, max_iterations=100):\n",
    "    \"\"\"\n",
    "    Merge small geocells (with < min_count images) into neighboring cells.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : GeoDataFrame\n",
    "        Input geocells with image_count column\n",
    "    min_count : int\n",
    "        Minimum image count threshold (default: 50)\n",
    "    max_iterations : int\n",
    "        Maximum number of iterations to prevent infinite loops (default: 100)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    GeoDataFrame with merged geocells\n",
    "    \"\"\"\n",
    "    gdf = gdf.copy()\n",
    "    \n",
    "    # Validation: check that image_count exists\n",
    "    if 'image_count' not in gdf.columns:\n",
    "        raise ValueError(\"GeoDataFrame must have 'image_count' column\")\n",
    "    \n",
    "    # Store original dtypes for proper reconstruction\n",
    "    col_names = gdf.drop(columns='geometry').columns.tolist()\n",
    "    dtypes = {col: gdf[col].dtype for col in col_names}\n",
    "    \n",
    "    # Keep arrays for speed\n",
    "    geom = gdf.geometry.values\n",
    "    counts = gdf[\"image_count\"].values\n",
    "    countries = gdf[\"GID_0\"].values\n",
    "    index_map = gdf.index.to_numpy()  # track \"alive\" indices\n",
    "    \n",
    "    # Store all original columns (except geometry) as DataFrame for better column handling\n",
    "    df_data = gdf.drop(columns='geometry').copy()\n",
    "    \n",
    "    count = 0\n",
    "    total_unmergeable_count = 0  # Track total count of unmergeable cells across all iterations\n",
    "\n",
    "    while True:\n",
    "        count += 1\n",
    "        print(f\"Iteration {count}\")\n",
    "        \n",
    "        small_mask = counts < min_count\n",
    "        if not small_mask.any():\n",
    "            print(\"No more small cells to merge\")\n",
    "            break\n",
    "            \n",
    "        if count > max_iterations:\n",
    "            print(f\"Reached maximum iterations ({max_iterations})\")\n",
    "            remaining_small = np.sum(small_mask)\n",
    "            print(f\"Warning: {remaining_small} small cells remain unmerged\")\n",
    "            break\n",
    "\n",
    "        # Build STRtree only once per iteration (fast!)\n",
    "        tree = STRtree(geom)\n",
    "        \n",
    "        # Mapping: small_id → target_id\n",
    "        merge_map = {}\n",
    "        # Mapping: target_id → list of geometry indices to union\n",
    "        groups = {}\n",
    "        # Track which cells are targets (to prevent them from being sources)\n",
    "        protected_targets = set()\n",
    "        # Track cells that can't find neighbors in this iteration\n",
    "        unmergeable_cells_this_iter = set()\n",
    "\n",
    "        small_indices = np.where(small_mask)[0]\n",
    "\n",
    "        # First pass: collect all merge decisions\n",
    "        for si in small_indices:\n",
    "            # Skip if this cell is already a target for another merge\n",
    "            if si in protected_targets:\n",
    "                continue\n",
    "                \n",
    "            small_geom = geom[si]\n",
    "            if small_geom is None:\n",
    "                continue\n",
    "\n",
    "            # R-tree candidate search\n",
    "            candidate_ids = tree.query(small_geom)\n",
    "            candidate_ids = [ci for ci in candidate_ids if ci != si]\n",
    "\n",
    "            if not candidate_ids:\n",
    "                unmergeable_cells_this_iter.add(si)\n",
    "                continue\n",
    "\n",
    "            # Filter by same country\n",
    "            same_country = [\n",
    "                ci for ci in candidate_ids \n",
    "                if countries[ci] == countries[si]\n",
    "            ]\n",
    "            if not same_country:\n",
    "                unmergeable_cells_this_iter.add(si)\n",
    "                continue\n",
    "\n",
    "            # Filter by intersects (touches unsafe)\n",
    "            valid = [\n",
    "                ci for ci in same_country\n",
    "                if geom[ci].intersects(small_geom)\n",
    "            ]\n",
    "            if not valid:\n",
    "                unmergeable_cells_this_iter.add(si)\n",
    "                continue\n",
    "\n",
    "            # Select best neighbor (highest image_count)\n",
    "            best = max(valid, key=lambda ci: counts[ci])\n",
    "            \n",
    "            # Skip if target is also small and will be processed (to avoid conflicts)\n",
    "            if best in small_indices and best not in protected_targets:\n",
    "                # Check if target will find a better neighbor\n",
    "                # For now, allow it but mark as protected\n",
    "                protected_targets.add(best)\n",
    "\n",
    "            merge_map[si] = best\n",
    "\n",
    "            if best not in groups:\n",
    "                groups[best] = [best]  # start with the target's own geom\n",
    "            groups[best].append(si)\n",
    "\n",
    "        if not merge_map:\n",
    "            print(\"No valid merges found in this iteration\")\n",
    "            break\n",
    "\n",
    "        print(f\"  Merging {len(merge_map)} cells into {len(groups)} targets\")\n",
    "\n",
    "        # Apply unions and aggregate data\n",
    "        for target, members in groups.items():\n",
    "            # Union geometries\n",
    "            new_geom = unary_union([geom[i] for i in members])\n",
    "            new_count = sum(counts[i] for i in members)\n",
    "\n",
    "            # Update geometry and count\n",
    "            geom[target] = new_geom\n",
    "            counts[target] = new_count\n",
    "            \n",
    "            # Aggregate other columns\n",
    "            # For string columns: keep target's value (or concatenate if needed)\n",
    "            # For numeric columns: sum (or average for non-count columns)\n",
    "            for col in col_names:\n",
    "                if col == 'image_count':\n",
    "                    continue  # Already handled\n",
    "                    \n",
    "                col_values = [df_data.iloc[i][col] for i in members]\n",
    "                \n",
    "                # Handle based on dtype\n",
    "                if df_data[col].dtype == 'object' or pd.api.types.is_string_dtype(df_data[col]):\n",
    "                    # For strings, keep target's value (first in members list is target)\n",
    "                    df_data.iloc[target, df_data.columns.get_loc(col)] = col_values[0]\n",
    "                elif pd.api.types.is_numeric_dtype(df_data[col]):\n",
    "                    # For numeric, sum (appropriate for counts) or could use mean\n",
    "                    if 'count' in col.lower() or 'size' in col.lower():\n",
    "                        valid_values = [v for v in col_values if pd.notna(v)]\n",
    "                        if valid_values:\n",
    "                            df_data.iloc[target, df_data.columns.get_loc(col)] = sum(valid_values)\n",
    "                        else:\n",
    "                            df_data.iloc[target, df_data.columns.get_loc(col)] = 0\n",
    "                    else:\n",
    "                        # For other numeric, use mean\n",
    "                        valid_values = [v for v in col_values if pd.notna(v)]\n",
    "                        if valid_values:\n",
    "                            df_data.iloc[target, df_data.columns.get_loc(col)] = np.mean(valid_values)\n",
    "                        else:\n",
    "                            df_data.iloc[target, df_data.columns.get_loc(col)] = np.nan\n",
    "                else:\n",
    "                    # For other types, keep target's value\n",
    "                    df_data.iloc[target, df_data.columns.get_loc(col)] = col_values[0]\n",
    "\n",
    "        # Drop merged-away polygons\n",
    "        # Only drop cells that are in merge_map (i.e., successfully merged)\n",
    "        # Cells that couldn't find neighbors are NOT in merge_map and should NOT be dropped\n",
    "        drop_ids = list(merge_map.keys())\n",
    "        \n",
    "        # Safety check: ensure unmergeable cells are never dropped\n",
    "        # This should never happen, but we check as a safeguard\n",
    "        unmergeable_in_drop = set(drop_ids) & unmergeable_cells_this_iter\n",
    "        if unmergeable_in_drop:\n",
    "            print(f\"  Warning: Attempted to drop {len(unmergeable_in_drop)} unmergeable cells - removing from drop list\")\n",
    "            drop_ids = [di for di in drop_ids if di not in unmergeable_cells_this_iter]\n",
    "        \n",
    "        # Track unmergeable cells count for reporting\n",
    "        if unmergeable_cells_this_iter:\n",
    "            total_unmergeable_count += len(unmergeable_cells_this_iter)\n",
    "            print(f\"  {len(unmergeable_cells_this_iter)} cells could not find valid neighbors (kept as-is)\")\n",
    "        \n",
    "        keep_mask = np.ones(len(geom), dtype=bool)\n",
    "        keep_mask[drop_ids] = False\n",
    "\n",
    "        geom = geom[keep_mask]\n",
    "        counts = counts[keep_mask]\n",
    "        countries = countries[keep_mask]\n",
    "        index_map = index_map[keep_mask]\n",
    "        df_data = df_data.iloc[keep_mask].reset_index(drop=True)\n",
    "\n",
    "    # Report unmergeable cells\n",
    "    if total_unmergeable_count > 0:\n",
    "        print(f\"\\nSummary: {total_unmergeable_count} cells across all iterations could not find valid neighbors to merge with\")\n",
    "        print(\"These cells remain in the output as-is (not deleted)\")\n",
    "\n",
    "    # Update image_count in df_data\n",
    "    df_data['image_count'] = counts\n",
    "\n",
    "    # Reconstruct final GeoDataFrame with proper dtypes\n",
    "    # Convert df_data back to dict, preserving dtypes\n",
    "    data_dict = {}\n",
    "    for col in col_names:\n",
    "        data_dict[col] = df_data[col].values\n",
    "    \n",
    "    data_dict['geometry'] = geom\n",
    "    \n",
    "    out = gpd.GeoDataFrame(data_dict, index=index_map[:len(geom)], crs=gdf.crs)\n",
    "    \n",
    "    # Ensure proper dtypes\n",
    "    for col, dtype in dtypes.items():\n",
    "        if col in out.columns:\n",
    "            try:\n",
    "                out[col] = out[col].astype(dtype)\n",
    "            except (ValueError, TypeError):\n",
    "                # If conversion fails, keep as is\n",
    "                pass\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d16ce4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "  Merging 33333 cells into 14915 targets\n",
      "  506 cells could not find valid neighbors (kept as-is)\n",
      "Iteration 2\n",
      "  Merging 6218 cells into 3219 targets\n",
      "  600 cells could not find valid neighbors (kept as-is)\n",
      "Iteration 3\n",
      "  Merging 908 cells into 589 targets\n",
      "  670 cells could not find valid neighbors (kept as-is)\n",
      "Iteration 4\n",
      "  Merging 99 cells into 83 targets\n",
      "  689 cells could not find valid neighbors (kept as-is)\n",
      "Iteration 5\n",
      "  Merging 5 cells into 4 targets\n",
      "  693 cells could not find valid neighbors (kept as-is)\n",
      "Iteration 6\n",
      "No valid merges found in this iteration\n",
      "\n",
      "Summary: 3158 cells across all iterations could not find valid neighbors to merge with\n",
      "These cells remain in the output as-is (not deleted)\n"
     ]
    }
   ],
   "source": [
    "merged_gdf = merge_small_cells_fast(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "548100ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gdf.to_file(\"../resources/gadm_merged.gpkg\", driver=\"GPKG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
